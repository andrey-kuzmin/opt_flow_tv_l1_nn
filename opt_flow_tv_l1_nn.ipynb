{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    import os\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin'\n",
    "\n",
    "    import sys\n",
    "    print sys.getrecursionlimit()\n",
    "    sys.setrecursionlimit(40000)\n",
    "    print sys.getrecursionlimit()\n",
    "    \n",
    "    import theano\n",
    "    import theano.tensor as T\n",
    "    import theano.tensor.signal.conv\n",
    "    import numpy as np\n",
    "    import scipy.io as sio\n",
    "    import time\n",
    "\n",
    "    from lasagne.layers import InputLayer\n",
    "    from lasagne.layers import DenseLayer\n",
    "    from lasagne.layers import NonlinearityLayer\n",
    "    from lasagne.layers import DropoutLayer\n",
    "    from lasagne.layers import Pool2DLayer\n",
    "    from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "    import lasagne.layers as ll\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    ###############################\n",
    "    n_filt_grad = 8;\n",
    "\n",
    "    filt_grad = np.zeros((n_filt_grad,1,3,3), dtype=np.float32)\n",
    "    bias_grad = np.zeros((n_filt_grad,), dtype=np.float32)\n",
    "\n",
    "    filt_grad[0,0,:,:] = [[0, 0, 0],\n",
    "                          [0, -1,1],\n",
    "                          [0, 0, 0]];\n",
    "\n",
    "    filt_grad[1,0,:,:] = [[0, 0, 0],\n",
    "                          [0, -1, 0],\n",
    "                          [0, 1, 0]];\n",
    "    filt_grad[2,0,:,:] = [[0, 0, 0],\n",
    "                          [0, -1,1],\n",
    "                          [0, 0, 0]];\n",
    "\n",
    "    filt_grad[3,0,:,:] = [[0, 0, 0],\n",
    "                          [0, -1, 0],\n",
    "                          [0, 1, 0]]; \n",
    "\n",
    "    filt_grad[4:8,:,:] = filt_grad[0:4,:,:]\n",
    "    \n",
    "    n_filt_div = 1;\n",
    "\n",
    "    filt_div = np.zeros((1,n_filt_grad,3,3), dtype=np.float32)\n",
    "    bias_div = np.zeros((1,), dtype=np.float32)\n",
    "\n",
    "    filt_div[0,0,:,:] =  [[0, 0, 0],\n",
    "                          [-1, 1, 0],\n",
    "                          [0, 0, 0]];\n",
    "\n",
    "    filt_div[0,1,:,:] =  [[0, -1, 0],\n",
    "                          [0, 1, 0],\n",
    "                          [0, 0, 0]]; \n",
    "    \n",
    "    filt_div[0,2,:,:] =  [[0, 0, 0],\n",
    "                          [-1, 1, 0],\n",
    "                          [0, 0, 0]];\n",
    "\n",
    "    filt_div[0,3,:,:] =  [[0, -1, 0],\n",
    "                          [0, 1, 0],\n",
    "                          [0, 0, 0]];\n",
    "    \n",
    "    filt_div = filt_div * float(2.0) / float(n_filt_grad);\n",
    "    \n",
    "    filt_div[0,4:8,:,:] = filt_div[0,0:4,:,:]\n",
    "    \n",
    "    print filt_div\n",
    "    print filt_grad\n",
    "    ###############################\n",
    "\n",
    "    def interpolate_varsize(im, x, y, out_height, out_width):\n",
    "        # *_f are floats\n",
    "        num_batch, height, width, channels = im.shape\n",
    "        height_f = T.cast(height, theano.config.floatX)\n",
    "        width_f = T.cast(width, theano.config.floatX)\n",
    "\n",
    "        n = height * width * num_batch;\n",
    "        \n",
    "        x = T.clip(x, 0, width_f - 1)\n",
    "        y = T.clip(y, 0, height_f - 1)\n",
    "\n",
    "        # obtain indices of the 2x2 pixel neighborhood surrounding the coordinates;\n",
    "        # we need those in floatX for interpolation and in int64 for indexing. for\n",
    "        # indexing, we need to take care they do not extend past the image.\n",
    "        x0_f = T.floor(x)\n",
    "        y0_f = T.floor(y)\n",
    "        x1_f = x0_f + 1.0\n",
    "        y1_f = y0_f + 1.0\n",
    "        x0 = T.cast(x0_f, 'int64')\n",
    "        y0 = T.cast(y0_f, 'int64')\n",
    "        x1 = T.cast(T.minimum(x1_f, width_f - 1), 'int64')\n",
    "        y1 = T.cast(T.minimum(y1_f, height_f - 1), 'int64')\n",
    "        \n",
    "        # The input is [num_batch, height, width, channels]. We do the lookup in\n",
    "        # the flattened input, i.e [num_batch*height*width, channels]. We need\n",
    "        # to offset all indices to match the flat version\n",
    "        dim2 = width\n",
    "        dim1 = width*height\n",
    "        base = T.repeat(\n",
    "            T.arange(num_batch, dtype='int64')*dim1, out_height*out_width)\n",
    "        \n",
    "        base_y0 = base + y0*dim2\n",
    "        base_y1 = base + y1*dim2\n",
    "        idx_a = base_y0 + x0\n",
    "        idx_b = base_y1 + x0\n",
    "        idx_c = base_y0 + x1\n",
    "        idx_d = base_y1 + x1\n",
    "\n",
    "        # use indices to lookup pixels for all samples\n",
    "        im_flat = im.reshape((-1, channels))\n",
    "        \n",
    "        Ia = im_flat[idx_a]\n",
    "        Ib = im_flat[idx_b]\n",
    "        Ic = im_flat[idx_c]\n",
    "        Id = im_flat[idx_d]\n",
    "\n",
    "        # calculate interpolated values\n",
    "        wa = ((x1_f-x) * (y1_f-y)).dimshuffle(0, 'x')\n",
    "        wb = ((x1_f-x) * (y-y0_f)).dimshuffle(0, 'x')\n",
    "        wc = ((x-x0_f) * (y1_f-y)).dimshuffle(0, 'x')\n",
    "        wd = ((x-x0_f) * (y-y0_f)).dimshuffle(0, 'x')\n",
    "        output = T.sum([wa*Ia, wb*Ib, wc*Ic, wd*Id], axis=0)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def interpolate_varsize_nn(im, x, y, out_height, out_width):\n",
    "        # *_f are floats\n",
    "        num_batch, height, width, channels = im.shape\n",
    "        height_f = T.cast(height, theano.config.floatX)\n",
    "        width_f = T.cast(width, theano.config.floatX)\n",
    "\n",
    "        n = height * width * num_batch;\n",
    "        \n",
    "        x = T.clip(x, 0, width_f - 1)\n",
    "        y = T.clip(y, 0, height_f - 1)\n",
    "\n",
    "        # obtain indices of the 2x2 pixel neighborhood surrounding the coordinates;\n",
    "        # we need those in floatX for interpolation and in int64 for indexing. for\n",
    "        # indexing, we need to take care they do not extend past the image.\n",
    "        \n",
    "        x0_f = T.round(x)\n",
    "        y0_f = T.round(y)\n",
    "        \n",
    "        x0 = T.cast(x0_f, 'int64')\n",
    "        y0 = T.cast(y0_f, 'int64')\n",
    "        \n",
    "        # The input is [num_batch, height, width, channels]. We do the lookup in\n",
    "        # the flattened input, i.e [num_batch*height*width, channels]. We need\n",
    "        # to offset all indices to match the flat version\n",
    "        dim2 = width\n",
    "        dim1 = width*height\n",
    "        base = T.repeat(\n",
    "            T.arange(num_batch, dtype='int64')*dim1, out_height*out_width)\n",
    "        \n",
    "        base_y0 = base + y0*dim2\n",
    "        idx = base_y0 + x0\n",
    "\n",
    "        # use indices to lookup pixels for all samples\n",
    "        im_flat = im.reshape((-1, channels))\n",
    "       \n",
    "        I = im_flat[idx]\n",
    "        \n",
    "        return I\n",
    "    \n",
    "    def _meshgrid(height, width):\n",
    "        x_t = T.dot(T.ones((height, 1),dtype='float32'),\n",
    "                T.arange(width, dtype='float32').dimshuffle('x', 0))\n",
    "        y_t = T.dot(T.arange(height, dtype='float32').dimshuffle(0, 'x'),\n",
    "                T.ones((1, width),dtype='float32'))\n",
    "\n",
    "        x_t_flat = x_t.reshape((1, -1))\n",
    "        y_t_flat = y_t.reshape((1, -1))\n",
    "\n",
    "        return (x_t_flat,y_t_flat)\n",
    "    \n",
    "    def _meshgrid_nonflat(height, width):\n",
    "        x_t = T.dot(T.ones((height, 1),dtype='float32'),\n",
    "                T.arange(width, dtype='float32').dimshuffle('x', 0))\n",
    "        y_t = T.dot(T.arange(height, dtype='float32').dimshuffle(0, 'x'),\n",
    "                T.ones((1, width),dtype='float32'))\n",
    "\n",
    "        return (x_t,y_t)\n",
    "\n",
    "    def warp(imgs, u, v):\n",
    "        num_batch, channels, height, width = imgs.shape\n",
    "        \n",
    "        [x_grid,y_grid] = _meshgrid_nonflat(height, width);\n",
    "        \n",
    "        x_grid_batch = T.tile(x_grid, (n_batch,1,1,1))\n",
    "        y_grid_batch = T.tile(y_grid, (n_batch,1,1,1))\n",
    "        \n",
    "        warped_grid_x = x_grid_batch + u;\n",
    "        warped_grid_y = y_grid_batch + v;\n",
    "\n",
    "        num_batch, num_channels, height, width = imgs.shape\n",
    "        # dimshuffle input to  (bs, height, width, channels)\n",
    "        input_dim = imgs.dimshuffle(0, 2, 3, 1)\n",
    "        input_grid_x = warped_grid_x.dimshuffle(0, 2, 3, 1).flatten();\n",
    "        input_grid_y = warped_grid_y.dimshuffle(0, 2, 3, 1).flatten();\n",
    "        \n",
    "        height_int = T.cast(height, 'int64')\n",
    "        width_int = T.cast(width, 'int64')\n",
    "        input_transformed = interpolate_varsize(input_dim, input_grid_x, input_grid_y, height_int, width_int)\n",
    "\n",
    "        output = T.reshape(input_transformed, (num_batch, height, width, num_channels))\n",
    "        output = output.dimshuffle(0, 3, 1, 2)\n",
    "        return output  \n",
    "    \n",
    "    def img_bca_deriv(I1, I2, u, v):\n",
    "        I2_warped = warp(I2, u, v);\n",
    "        delta = 0.5 * T.ones_like(u,dtype='float32');\n",
    "        u_m = u - delta;\n",
    "        u_p = u + delta;\n",
    "        v_m = v - delta;\n",
    "        v_p = v + delta;\n",
    "        \n",
    "        I2_x_m = warp(I2, u_m, v);\n",
    "        I2_y_m = warp(I2, u, v_m);\n",
    "        I2_x_p = warp(I2, u_p, v);\n",
    "        I2_y_p = warp(I2, u, v_p);\n",
    "        \n",
    "        Ix = I2_x_p - I2_x_m;\n",
    "        Iy = I2_y_p - I2_y_m;\n",
    "        \n",
    "        It = I2_warped - I1;\n",
    "        \n",
    "        return(Ix,Iy,It)\n",
    "    \n",
    "    def imresize(imgs, height_new, width_new):\n",
    "        num_batch, num_channels, height, width = imgs.shape\n",
    "        \n",
    "        out_height = T.cast(height_new, 'int64')\n",
    "        out_width = T.cast(width_new, 'int64')\n",
    "        \n",
    "        [x_grid,y_grid] = _meshgrid_nonflat(out_height, out_width);\n",
    "        x_s = T.tile(x_grid, (n_batch,1,1,1))\n",
    "        y_s = T.tile(y_grid, (n_batch,1,1,1))\n",
    "        \n",
    "        height_f = T.cast(height, dtype='float32')\n",
    "        width_f = T.cast(width, dtype='float32')\n",
    "        \n",
    "        height_new_f = T.cast(out_height, dtype='float32')\n",
    "        width_new_f = T.cast(out_width, dtype='float32')\n",
    "        \n",
    "        x_s_flat = x_s.flatten() * (width_f-1.0) /  (width_new_f-1.0)\n",
    "        y_s_flat = y_s.flatten() * (height_f-1.0) / (height_new_f-1.0)\n",
    "        \n",
    "        input_dim = imgs.dimshuffle(0, 2, 3, 1)\n",
    "        input_transformed = interpolate_varsize(input_dim, x_s_flat, y_s_flat, out_height, out_width)\n",
    "                \n",
    "        output = T.reshape(input_transformed, (num_batch, out_height, out_width, num_channels))\n",
    "        output = output.dimshuffle(0, 3, 1, 2)  # dimshuffle to conv format\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def imresize_nn(imgs, height_new, width_new):\n",
    "        num_batch, num_channels, height, width = imgs.shape\n",
    "        \n",
    "        out_height = T.cast(height_new, 'int64')\n",
    "        out_width = T.cast(width_new, 'int64')\n",
    "        \n",
    "        [x_grid,y_grid] = _meshgrid_nonflat(out_height, out_width);\n",
    "        x_s = T.tile(x_grid, (n_batch,1,1,1))\n",
    "        y_s = T.tile(y_grid, (n_batch,1,1,1))\n",
    "        \n",
    "        height_f = T.cast(height, theano.config.floatX)\n",
    "        width_f = T.cast(width, theano.config.floatX)\n",
    "        \n",
    "        height_new_f = T.cast(out_height, theano.config.floatX)\n",
    "        width_new_f = T.cast(out_width, theano.config.floatX)\n",
    "        \n",
    "        x_s_flat = x_s.flatten() * (width_f-1.0) /  (width_new_f-1.0)\n",
    "        y_s_flat = y_s.flatten() * (height_f-1.0) / (height_new_f-1.0)\n",
    "        \n",
    "        input_dim = imgs.dimshuffle(0, 2, 3, 1)\n",
    "        input_transformed = interpolate_varsize_nn(input_dim, x_s_flat, y_s_flat, out_height, out_width)\n",
    "                \n",
    "        output = T.reshape(input_transformed, (num_batch, out_height, out_width, num_channels))\n",
    "        output = output.dimshuffle(0, 3, 1, 2)  # dimshuffle to conv format\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def data_term_bca_proximal(u, v, u0, v0, I_x, I_y, I_t, theta, lmbd, beta):\n",
    "        I_grad_sqr = T.maximum(1e-09, I_x*I_x + I_y*I_y + beta*beta);    \n",
    "            \n",
    "        rho = I_t + (u - u0) * I_x + (v - v0) * I_y;\n",
    "        \n",
    "        threshold = theta * lmbd * I_grad_sqr;\n",
    "        \n",
    "        mask1 = (rho < -1.0 * threshold);\n",
    "        mask2 = (rho > threshold);\n",
    "        mask3 = (abs(rho) < threshold);\n",
    "\n",
    "        u = u + theta * lmbd * I_x * mask1; \n",
    "        v = v + theta * lmbd * I_y * mask1;\n",
    "        \n",
    "        u = u - theta * lmbd * I_x * mask2; \n",
    "        v = v - theta * lmbd * I_y * mask2;\n",
    "        \n",
    "        u = u - (rho * I_x / I_grad_sqr) * mask3; \n",
    "        v = v - (rho * I_y / I_grad_sqr) * mask3;\n",
    "        \n",
    "        return (u,v)\n",
    "        \n",
    "    def reproject_dual(dual_u, dual_v, beta):\n",
    "        norm_sqr = T.sqr(dual_v[:,0,:,:]) + T.sqr(dual_v[:,1,:,:]) + T.sqr(dual_u[:,2,:,:]) + T.sqr(dual_u[:,3,:,:]) + T.sqr(dual_v[:,4,:,:]) + T.sqr(dual_v[:,5,:,:]) + T.sqr(dual_u[:,6,:,:]) + T.sqr(dual_u[:,7,:,:]); \n",
    "        \n",
    "        reprojection = T.maximum(T.sqrt(norm_sqr+beta*beta),1.0)\n",
    "        \n",
    "        dual_u_unit = dual_u / reprojection[:,np.newaxis,:,:];\n",
    "        dual_v_unit = dual_v / reprojection[:,np.newaxis,:,:];\n",
    "                \n",
    "        return (dual_u_unit,dual_v_unit)\n",
    "    \n",
    "    def dual_update(u, v, dual_u, dual_v, theta, lipschitz_c, beta):\n",
    "        grad_u = ConvLayer(InputLayer(shape=(None, 1, None, None), input_var=u), \n",
    "                           name = \"l_conv1_1\", num_filters=n_filt_grad, filter_size=3, pad=1,\n",
    "                           nonlinearity=None, flip_filters=False);\n",
    "        \n",
    "        grad_v = ConvLayer(InputLayer(shape=(None, 1, None, None), input_var=v), \n",
    "                           name = \"l_conv1_1\", num_filters=n_filt_grad, filter_size=3, pad=1,\n",
    "                           nonlinearity=None, flip_filters=False);\n",
    "\n",
    "        grad_u.W.set_value(filt_grad)\n",
    "        grad_u.b.set_value(bias_grad)\n",
    "        \n",
    "        grad_v.W.set_value(filt_grad)\n",
    "        grad_v.b.set_value(bias_grad)\n",
    "                \n",
    "        dual_u_new = dual_u + 1 / lipschitz_c * theta * ll.get_output(grad_u);\n",
    "        dual_v_new = dual_v + 1 / lipschitz_c * theta * ll.get_output(grad_v);\n",
    "            \n",
    "        [dual_u_new, dual_v_new] = reproject_dual(dual_u_new, dual_v_new, beta);\n",
    "        \n",
    "        return (dual_u_new, dual_v_new, grad_u, grad_v)\n",
    "    \n",
    "    def primal_update(u, v, dual_u, dual_v, theta):\n",
    "        div_dual_u = ConvLayer(InputLayer(shape=(None, n_filt_grad, None, None), input_var=dual_u), \n",
    "                               name = \"l_conv1_2\", num_filters=n_filt_div, filter_size=3, pad=1,\n",
    "                               nonlinearity=None, flip_filters=False);\n",
    "        \n",
    "        div_dual_v = ConvLayer(InputLayer(shape=(None, n_filt_grad, None, None), input_var=dual_v), \n",
    "                               name = \"l_conv1_2\", num_filters=n_filt_div, filter_size=3, pad=1,\n",
    "                               nonlinearity=None, flip_filters=False);\n",
    "\n",
    "        div_dual_u.W.set_value(filt_div)\n",
    "        div_dual_u.b.set_value(bias_div)\n",
    "        \n",
    "        div_dual_v.W.set_value(filt_div)\n",
    "        div_dual_v.b.set_value(bias_div)\n",
    "        \n",
    "        u_new = u + theta * ll.get_output(div_dual_u);\n",
    "        v_new = v + theta * ll.get_output(div_dual_v);\n",
    "        \n",
    "        return (u_new, v_new, div_dual_u, div_dual_v);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin'\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.signal.conv\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import time\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "\n",
    "from lasagne.init import Constant\n",
    "\n",
    "import lasagne.layers as ll\n",
    "from lasagne.layers import ConcatLayer\n",
    "import lasagne.updates\n",
    "\n",
    "h = 436;\n",
    "w = 1024;\n",
    "\n",
    "ratio = 0.8\n",
    "\n",
    "n_scales = 15;\n",
    "\n",
    "h_scales = [];\n",
    "w_scales = [];\n",
    "\n",
    "h_scale = h;\n",
    "w_scale = w;\n",
    "\n",
    "for i_scale in range(0, n_scales):\n",
    "    h_scales = [h_scale] + h_scales;\n",
    "    w_scales = [w_scale] + w_scales;\n",
    "\n",
    "    h_scale = int(h_scale * ratio);\n",
    "    w_scale = int(w_scale * ratio);\n",
    "\n",
    "print 'image pyramid:'    \n",
    "    \n",
    "print h_scales\n",
    "print w_scales\n",
    "\n",
    "n_batch = 4;\n",
    "n_inner_iter = 10;\n",
    "\n",
    "print '-----------------'\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "params_lasagne = []\n",
    "\n",
    "theta = T.scalar(dtype='float32');\n",
    "lmbd = T.scalar(dtype='float32');\n",
    "beta = T.scalar(dtype='float32');\n",
    "lipschitz_c = T.scalar(dtype='float32');\n",
    "\n",
    "lr = T.scalar(dtype='float32');\n",
    "\n",
    "I1_batch = T.tensor4(dtype='float32');\n",
    "I2_batch = T.tensor4(dtype='float32');\n",
    "\n",
    "I1_batch_scale_lst = [];\n",
    "I2_batch_scale_lst = [];\n",
    "\n",
    "for i_scale in range(0, n_scales-1):\n",
    "    I1_batch_coarse = imresize(I1_batch, h_scales[i_scale], w_scales[i_scale]);\n",
    "    I2_batch_coarse = imresize(I2_batch, h_scales[i_scale], w_scales[i_scale]);\n",
    "    \n",
    "    I1_batch_scale_lst.append(I1_batch_coarse);\n",
    "    I2_batch_scale_lst.append(I2_batch_coarse);\n",
    "\n",
    "I1_batch_scale_lst = I1_batch_scale_lst + [I1_batch];  \n",
    "I2_batch_scale_lst = I2_batch_scale_lst + [I2_batch];      \n",
    "    \n",
    "u_gt = T.tensor4(dtype='float32');\n",
    "v_gt = T.tensor4(dtype='float32');\n",
    "\n",
    "lr = T.scalar(dtype='float32');\n",
    "\n",
    "u_init = T.zeros_like(I1_batch_scale_lst[0],dtype='float32');\n",
    "v_init = T.zeros_like(I1_batch_scale_lst[0],dtype='float32');\n",
    "\n",
    "dual_u_init = T.tile(T.zeros_like(I1_batch_scale_lst[0],dtype='float32'),(1,n_filt_grad,1,1))\n",
    "dual_v_init = T.tile(T.zeros_like(I1_batch_scale_lst[0],dtype='float32'),(1,n_filt_grad,1,1))\n",
    "\n",
    "################## SCALE ITERATION ######################\n",
    "for i_scale in range(0,n_scales):\n",
    "    print '-----------------'\n",
    "    print 'scale ', i_scale\n",
    "    \n",
    "    if (i_scale == 0):\n",
    "        print 'initialize with zeros'\n",
    "        u = u_init;\n",
    "        v = v_init;\n",
    "        \n",
    "        dual_u = dual_u_init;\n",
    "        dual_v = dual_v_init;\n",
    "    else:    \n",
    "        rescale_ratio_h = float(h_scales[i_scale]) / float(h_scales[i_scale-1]); \n",
    "        rescale_ratio_w = float(w_scales[i_scale]) / float(w_scales[i_scale-1]);\n",
    "        \n",
    "        u = u * rescale_ratio_w;\n",
    "        v = v * rescale_ratio_h;\n",
    "        \n",
    "        print 'rescale, ratio = ', rescale_ratio_h\n",
    "\n",
    "    u0 = u;\n",
    "    v0 = v;     \n",
    "        \n",
    "    [Ix,Iy,It] = img_bca_deriv(I1_batch_scale_lst[i_scale], I2_batch_scale_lst[i_scale], u0, v0);\n",
    "\n",
    "    for it in range(0,n_inner_iter):\n",
    "        [u,v] = data_term_bca_proximal(u, v, u0, v0, Ix, Iy, It, theta, lmbd, beta);\n",
    "        \n",
    "        [dual_u, dual_v, div_u_layer, div_v_layer] = dual_update(u, v, dual_u, dual_v, theta, lipschitz_c, beta);\n",
    "         \n",
    "        [u, v, grad_u_layer, grad_v_layer] = primal_update(u, v, dual_u, dual_v, theta);\n",
    "        \n",
    "        #[u,v] = data_term_bca_proximal(u, v, u0, v0, Ix, Iy, It, theta, lmbd, beta);\n",
    "        \n",
    "        #u_ = 2.0 * u - u_;\n",
    "        #v_ = 2.0 * v - v_;\n",
    "    \n",
    "        params_lasagne += ll.get_all_params(grad_u_layer) + ll.get_all_params(grad_v_layer) + ll.get_all_params(div_u_layer) + ll.get_all_params(div_v_layer);\n",
    "    ##############\n",
    "        \n",
    "    # rescale    \n",
    "    if (i_scale <  n_scales - 1):  \n",
    "        u = imresize_nn(u, h_scales[i_scale+1], w_scales[i_scale+1]);\n",
    "        v = imresize_nn(v, h_scales[i_scale+1], w_scales[i_scale+1]);\n",
    "        dual_v = imresize_nn(dual_v, h_scales[i_scale+1], w_scales[i_scale+1]);\n",
    "        dual_u = imresize_nn(dual_u, h_scales[i_scale+1], w_scales[i_scale+1]);\n",
    "\n",
    "################## END SCALE ITERATION #####################\n",
    "\n",
    "theano_optical_flow_fn = theano.function(inputs=[I1_batch,I2_batch,theta,lmbd,beta,lipschitz_c], outputs=[u,v], on_unused_input='ignore');\n",
    "\n",
    "diff = T.sqrt(T.sqr(u-u_gt) + T.sqr(v-v_gt) + 1.0E-8);\n",
    "\n",
    "L = T.mean(diff.flatten());\n",
    "\n",
    "theano_loss_fn = theano.function(inputs=[I1_batch,I2_batch,u_gt,v_gt,theta,lmbd,beta,lipschitz_c], outputs=[L,u,v], on_unused_input='ignore');\n",
    "\n",
    "updates = lasagne.updates.adam(L, params_lasagne, learning_rate=lr);\n",
    "\n",
    "theano_train_fn = theano.function(inputs=[I1_batch,I2_batch,u_gt,v_gt,theta,lmbd,beta,lipschitz_c,lr], \n",
    "                                  outputs=[L], updates = updates,on_unused_input='ignore');\n",
    "print 'parameters total:'\n",
    "print len(params_lasagne)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print 'time:'\n",
    "print toc - tic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
